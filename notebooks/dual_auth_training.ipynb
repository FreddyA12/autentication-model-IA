{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento Dual: Rostro + Voz",
        "",
        "Este cuaderno orquesta el pipeline completo para entrenar y validar los modelos",
        "de reconocimiento facial y de voz. Ejecuta las celdas en orden para reproducir",
        "el flujo o reutilizarlo como guía mientras ajustas hiperparámetros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Preparación del entorno",
        "- Recomiendo crear/activar un entorno virtual antes de abrir el cuaderno.",
        "- Instala dependencias con `pip install -r requirements.txt`.",
        "- Si vas a usar GPU, confirma que TensorFlow reconoce tus dispositivos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "import os",
        "from pathlib import Path",
        "",
        "BASE_DIR = Path.cwd()",
        "print(f\"Proyecto: {BASE_DIR}\")",
        "print(f\"Modelos existentes: {list((BASE_DIR / 'dataset' / 'models').glob('*.keras'))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Pipeline de reconocimiento facial",
        "Los pasos replican los scripts `dataset/scripts/1-4_*.py`. Ejecuta cada celda según lo necesites."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 1.1 Extraer frames desde los videos originales",
        "!python dataset/scripts/1_extract_frames.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 1.2 Detectar rostros con MTCNN y normalizar imágenes",
        "!python dataset/scripts/2_balance_and_preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 1.3 Entrenar el modelo CNN de rostros",
        "!python dataset/scripts/3_train_model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 1.4 Pruebas rápidas del modelo entrenado",
        "!python dataset/scripts/4_predict.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Pipeline de reconocimiento de voz",
        "Generamos audios, espectrogramas y entrenamos el CNN equivalente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 2.1 Extraer WAV desde los videos",
        "!python dataset/scripts/5_extract_audio.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 2.2 Construir espectrogramas log-mel para cada usuario",
        "!python dataset/scripts/6_build_mel_spectrograms.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 2.3 Entrenar el modelo de voz",
        "!python dataset/scripts/7_train_voice_model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "# 2.4 Evaluación rápida con muestras de audio de prueba",
        "!python dataset/scripts/8_predict_voice.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Inferencia y verificación conjunta",
        "Puedes cargar ambos modelos mediante las clases `FaceRecognizer`, `VoiceRecognizer`",
        "y `DualAuthenticator` para componerse en un flujo integrado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "",
        "from pathlib import Path",
        "",
        "from src.dual_auth import FaceRecognizer, VoiceRecognizer, DualAuthenticator",
        "",
        "FACE_MODEL = Path(\"dataset/models/faces_cnn_best.keras\")",
        "FACE_CLASSES = Path(\"dataset/models/class_indices.json\")",
        "VOICE_MODEL = Path(\"dataset/models/voice_cnn_best.keras\")",
        "VOICE_CLASSES = Path(\"dataset/models/voice_class_indices.json\")",
        "",
        "if FACE_MODEL.exists() and VOICE_MODEL.exists():",
        "    face_recognizer = FaceRecognizer(FACE_MODEL, FACE_CLASSES)",
        "    voice_recognizer = VoiceRecognizer(VOICE_MODEL, VOICE_CLASSES)",
        "    print(\"Modelos cargados. Usa DualAuthenticator en tu propia lógica de captura.\")",
        "else:",
        "    print(\"Entrena ambos modelos antes de continuar.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo en tiempo real (opcional)",
        "Tras entrenar ambos modelos puedes lanzar desde la terminal:",
        "",
        "```bash",
        "python -m src.dual_auth.run_dual_auth_live \\",
        "    --identity <usuario> \\",
        "    --face-threshold 0.75 \\",
        "    --voice-threshold 0.65",
        "```",
        "",
        "La demo usa webcam + micrófono para combinar ambas señales."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}