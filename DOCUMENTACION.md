# üìö Documentaci√≥n del Sistema de Reconocimiento Facial

## üéØ Descripci√≥n General

Este sistema permite reconocer rostros de personas espec√≠ficas (Alison, Freddy, Isma) y detectar personas desconocidas. Utiliza **FaceNet** para extraer caracter√≠sticas faciales y **SVM** para clasificar.

---

## üìÅ Estructura del Proyecto

```
APE3/
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_raw/           # Im√°genes originales (sin procesar)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alison/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ freddy/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ isma/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_clean/         # Im√°genes procesadas y alineadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alison/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ freddy/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ isma/
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/            # Vectores de caracter√≠sticas extra√≠dos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ face_embeddings.pkl
‚îÇ   ‚îú‚îÄ‚îÄ models/                # Modelos entrenados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ face_svm.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ face_embedding_classifier.keras
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ class_indices.json
‚îÇ   ‚îú‚îÄ‚îÄ test_data/             # Im√°genes para probar el sistema
‚îÇ   ‚îú‚îÄ‚îÄ videos/                # Videos para extraer frames
‚îÇ   ‚îî‚îÄ‚îÄ scripts/               # Scripts de procesamiento
‚îî‚îÄ‚îÄ src/                       # C√≥digo fuente de la aplicaci√≥n
```

---

## üîÑ Pipeline de Entrenamiento

### Paso 1: Preparar Videos/Im√°genes

Coloca los videos o im√°genes de cada persona en:
```
dataset/videos/
```

O directamente las im√°genes en:
```
dataset/dataset_raw/{nombre_persona}/
```

---

### Paso 2: Extraer Frames de Videos (Opcional)

Si tienes videos, extrae los frames:

```powershell
python dataset/scripts/1_extract_frames.py
```

**¬øQu√© hace?**
- Lee los videos de `dataset/videos/`
- Extrae frames cada cierto intervalo
- Guarda las im√°genes en `dataset/dataset_raw/{persona}/`

---

### Paso 3: Preprocesar y Alinear Rostros

```powershell
python dataset/scripts/2_preprocess_aligned.py
```

**¬øQu√© hace?**
1. Lee im√°genes de `dataset/dataset_raw/`
2. Detecta rostros usando **MTCNN**
3. Alinea las caras usando los landmarks de los ojos
4. Extrae **embeddings de 512 dimensiones** con FaceNet
5. Guarda:
   - Im√°genes alineadas en `dataset/dataset_clean/`
   - Embeddings en `dataset/embeddings/face_embeddings.pkl`

**Salida esperada:**
```
Procesando: alison (430 im√°genes)
  ‚úì Procesadas: 429
  ‚úó Fallidas: 1

Distancias promedio entre embeddings:
  alison: 0.798 ¬± 0.160
  freddy: 0.653 ¬± 0.167
  isma: 0.665 ¬± 0.169

Distancias entre personas diferentes:
  alison vs freddy: 1.382
  alison vs isma: 1.122
  freddy vs isma: 1.208
```

> **Nota:** Las distancias intra-clase (~0.6-0.8) deben ser menores que las inter-clase (~1.1-1.4) para un buen reconocimiento.

---

### Paso 4: Entrenar el Clasificador

```powershell
python dataset/scripts/3_train_with_embeddings.py
```

**¬øQu√© hace?**
1. Carga los embeddings de `dataset/embeddings/`
2. Entrena un clasificador **SVM** (Support Vector Machine)
3. Entrena una **red neuronal** peque√±a como alternativa
4. Guarda los modelos en `dataset/models/`

**Salida esperada:**
```
ENTRENANDO CLASIFICADOR SVM
  Accuracy: 100.00%
  Validaci√≥n cruzada: 99.93% ¬± 0.15%

ENTRENANDO CLASIFICADOR NEURAL
  Accuracy: 100.00%
```

**Modelos generados:**
- `face_svm.pkl` - Clasificador SVM
- `face_embedding_classifier.keras` - Red neuronal
- `class_indices.json` - Mapeo de clases

---

### Paso 5: Probar el Sistema

```powershell
python dataset/scripts/4_predict_embeddings.py
```

**¬øQu√© hace?**
1. Carga los modelos entrenados
2. Prueba con im√°genes de `dataset/test_data/`
3. Prueba con muestras aleatorias del dataset

**Salida esperada:**
```
PROBANDO IM√ÅGENES EXTERNAS
‚úÖ alison.jpg    ‚Üí alison (conf: 99.6%, dist: 0.58)
‚úÖ freddy2.jpg   ‚Üí freddy (conf: 98.8%, dist: 0.52)
‚úÖ isma.jpg      ‚Üí isma (conf: 100.0%, dist: 0.46)
‚ö†Ô∏è  rafa.jpg     ‚Üí DESCONOCIDO (conf: 67.1%, dist: 1.23)
‚ö†Ô∏è  william.jpg  ‚Üí DESCONOCIDO (conf: 44.6%, dist: 0.86)
```

---

## üìã Resumen de Comandos

| Paso | Comando | Descripci√≥n |
|------|---------|-------------|
| 1 | `python dataset/scripts/1_extract_frames.py` | Extrae frames de videos |
| 2 | `python dataset/scripts/2_preprocess_aligned.py` | Preprocesa y extrae embeddings |
| 3 | `python dataset/scripts/3_train_with_embeddings.py` | Entrena clasificador |
| 4 | `python dataset/scripts/4_predict_embeddings.py` | Prueba el sistema |

---

## ‚öôÔ∏è Configuraci√≥n y Umbrales

### En `4_predict_embeddings.py`:

```python
CONFIDENCE_THRESHOLD = 0.60  # M√≠nima confianza para aceptar predicci√≥n
DISTANCE_THRESHOLD = 1.0     # M√°xima distancia para considerar conocido
```

- Si la **confianza < 60%** ‚Üí Se marca como DESCONOCIDO
- Si la **distancia > 1.0** ‚Üí Se marca como DESCONOCIDO

### Ajustar umbrales:
- **Aumentar `CONFIDENCE_THRESHOLD`** ‚Üí M√°s estricto (menos falsos positivos)
- **Disminuir `DISTANCE_THRESHOLD`** ‚Üí M√°s estricto

---

## üÜï Agregar una Nueva Persona

1. Crear carpeta con el nombre en `dataset/dataset_raw/`:
   ```
   dataset/dataset_raw/nueva_persona/
   ```

2. Agregar im√°genes (m√≠nimo 100, idealmente 300+)

3. Ejecutar el pipeline completo:
   ```powershell
   python dataset/scripts/2_preprocess_aligned.py
   python dataset/scripts/3_train_with_embeddings.py
   ```

4. Verificar:
   ```powershell
   python dataset/scripts/4_predict_embeddings.py
   ```

---

## üîß Tecnolog√≠as Utilizadas

| Componente | Tecnolog√≠a | Prop√≥sito |
|------------|------------|-----------|
| Detecci√≥n de rostros | MTCNN | Detecta y alinea caras |
| Extracci√≥n de features | FaceNet (InceptionResnetV1) | Genera embeddings de 512D |
| Clasificaci√≥n | SVM / Red Neural | Identifica a la persona |
| Framework | TensorFlow + PyTorch | Deep Learning |

---

## üìä M√©tricas de Calidad

### Distancias de Embeddings:
- **Intra-clase** (misma persona): Debe ser **< 1.0**
- **Inter-clase** (diferentes personas): Debe ser **> 1.0**
- **Ratio ideal**: Inter/Intra > 1.5

### Resultados actuales:
| Persona | Distancia Intra-clase |
|---------|----------------------|
| alison | 0.798 ¬± 0.160 |
| freddy | 0.653 ¬± 0.167 |
| isma | 0.665 ¬± 0.169 |

| Comparaci√≥n | Distancia Inter-clase |
|-------------|----------------------|
| alison vs freddy | 1.382 |
| alison vs isma | 1.122 |
| freddy vs isma | 1.208 |

---

## ‚ùì Soluci√≥n de Problemas

### El sistema no detecta rostros
- Verificar que las im√°genes tengan buena iluminaci√≥n
- Verificar que los rostros no est√©n muy peque√±os o borrosos
- El rostro debe ocupar al menos 40x40 p√≠xeles

### Baja precisi√≥n
- Agregar m√°s im√°genes de entrenamiento
- Asegurar variedad: diferentes √°ngulos, iluminaci√≥n, expresiones
- Verificar que las distancias inter-clase sean mayores que intra-clase

### Muchos falsos positivos (reconoce desconocidos como conocidos)
- Aumentar `CONFIDENCE_THRESHOLD` (ej: 0.70)
- Disminuir `DISTANCE_THRESHOLD` (ej: 0.9)

### Muchos falsos negativos (no reconoce personas conocidas)
- Disminuir `CONFIDENCE_THRESHOLD` (ej: 0.50)
- Aumentar `DISTANCE_THRESHOLD` (ej: 1.2)
- Agregar m√°s im√°genes de esa persona

---

## üìù Notas Importantes

1. **FaceNet es un modelo preentrenado** en millones de caras (VGGFace2). Solo el clasificador SVM/Neural se entrena con tus datos.

2. **Cantidad de datos recomendada:**
   - M√≠nimo: 100 im√°genes por persona
   - √ìptimo: 300-500 im√°genes por persona
   - Las im√°genes deben tener variedad

3. **Formato de im√°genes:** JPG, PNG o JPEG

4. **Tama√±o procesado:** 160x160 p√≠xeles (autom√°tico)

---

## üöÄ Uso en Producci√≥n

Para usar el sistema en tiempo real (c√°mara web), ejecuta:

```powershell
python src/dual_auth/run_dual_auth_live.py
```

Esto activar√° la c√°mara y realizar√° reconocimiento facial en vivo.
